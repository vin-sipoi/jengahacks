name: Automated Database Backup

on:
  schedule:
    # Run daily at 2 AM UTC (5 AM EAT)
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      project:
        description: 'Supabase project to backup (production/staging)'
        required: true
        default: 'production'
        type: choice
        options:
          - production
          - staging

jobs:
  backup-production:
    name: Backup Production Database
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || (github.event_name == 'workflow_dispatch' && github.event.inputs.project == 'production')
    # Note: Create 'production' environment in GitHub Settings â†’ Environments if protection rules are needed
    # environment:
    #   name: production
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Supabase CLI
        uses: supabase/setup-cli@v1
        with:
          version: latest

      - name: Check Supabase Secret
        run: |
          if [ -z "${{ secrets.SUPABASE_ACCESS_TOKEN }}" ]; then
            echo "âŒ SUPABASE_ACCESS_TOKEN is not set in GitHub Secrets"
            exit 1
          fi

      - name: Create backup directory
        run: mkdir -p backups/database

      - name: Backup production database
        run: |
          BACKUP_FILE="backups/database/db_backup_prod_$(date +%Y%m%d_%H%M%S).sql"
          supabase db dump --project-ref ${{ secrets.SUPABASE_PROJECT_REF }} > "$BACKUP_FILE"
          gzip "$BACKUP_FILE"
          echo "BACKUP_FILE=${BACKUP_FILE}.gz" >> $GITHUB_ENV
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
          SUPABASE_PROJECT_REF: ${{ secrets.SUPABASE_PROJECT_REF }}

      - name: Verify backup integrity
        run: |
          if gzip -t "$BACKUP_FILE"; then
            echo "âœ… Backup integrity check passed"
          else
            echo "âŒ Backup integrity check failed"
            exit 1
          fi

      - name: Get backup size
        run: |
          BACKUP_SIZE=$(du -h "$BACKUP_FILE" | cut -f1)
          echo "ðŸ“¦ Backup size: $BACKUP_SIZE"
          echo "BACKUP_SIZE=$BACKUP_SIZE" >> $GITHUB_ENV

      - name: Count tables in backup
        run: |
          TABLE_COUNT=$(gzip -dc "$BACKUP_FILE" | grep -c "CREATE TABLE" || echo "0")
          echo "ðŸ“Š Tables in backup: $TABLE_COUNT"
          echo "TABLE_COUNT=$TABLE_COUNT" >> $GITHUB_ENV

      - name: Upload backup to artifacts
        uses: actions/upload-artifact@v4
        with:
          name: production-db-backup-${{ github.run_number }}
          path: ${{ env.BACKUP_FILE }}
          retention-days: 30

      - name: Upload to cloud storage (AWS S3)
        if: env.AWS_ACCESS_KEY_ID != ''
        continue-on-error: true
        run: |
          aws s3 cp "$BACKUP_FILE" s3://${{ secrets.S3_BACKUP_BUCKET }}/database/production/$(basename "$BACKUP_FILE")
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.u }}
          AWS_DEFAULT_REGION: ${{ secrets.AWS_REGION || 'us-east-1' }}

      - name: Upload to cloud storage (Google Cloud Storage)
        if: env.GCS_BACKUP_BUCKET != '' && env.AWS_ACCESS_KEY_ID == ''
        continue-on-error: true
        run: |
          echo "${{ secrets.GCS_SERVICE_ACCOUNT_KEY }}" | base64 -d > gcs-key.json
          gcloud auth activate-service-account --key-file=gcs-key.json
          gsutil cp "$BACKUP_FILE" gs://${{ secrets.GCS_BACKUP_BUCKET }}/database/production/$(basename "$BACKUP_FILE")
        env:
          GCS_BACKUP_BUCKET: ${{ secrets.GCS_BACKUP_BUCKET }}

      - name: Cleanup old backups
        run: |
          # Keep only last 30 days of backups in artifacts
          # Cloud storage should handle its own retention
          echo "ðŸ§¹ Cleanup handled by artifact retention (30 days)"

      - name: Backup Summary
        if: always()
        run: |
          echo "## Production Database Backup Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Backup completed successfully" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ“¦ Backup file: \`${{ env.BACKUP_FILE }}\`" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ“Š Size: ${{ env.BACKUP_SIZE }}" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ“‹ Tables: ${{ env.TABLE_COUNT }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Timestamp:** $(date -u +'%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
          echo "**Run:** #${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY

  backup-staging:
    name: Backup Staging Database
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.project == 'staging'
    # Note: Create 'staging' environment in GitHub Settings â†’ Environments if protection rules are needed
    # environment:
    #   name: staging
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Supabase CLI
        uses: supabase/setup-cli@v1
        with:
          version: latest

      - name: Check Supabase Secret
        run: |
          if [ -z "${{ secrets.SUPABASE_ACCESS_TOKEN }}" ]; then
            echo "âŒ SUPABASE_ACCESS_TOKEN is not set in GitHub Secrets"
            exit 1
          fi

      - name: Create backup directory
        run: mkdir -p backups/database

      - name: Backup staging database
        run: |
          BACKUP_FILE="backups/database/db_backup_staging_$(date +%Y%m%d_%H%M%S).sql"
          supabase db dump --project-ref ${{ secrets.STAGING_SUPABASE_PROJECT_REF }} > "$BACKUP_FILE"
          gzip "$BACKUP_FILE"
          echo "BACKUP_FILE=${BACKUP_FILE}.gz" >> $GITHUB_ENV
        env:
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
          STAGING_SUPABASE_PROJECT_REF: ${{ secrets.STAGING_SUPABASE_PROJECT_REF }}

      - name: Verify backup integrity
        run: |
          if gzip -t "$BACKUP_FILE"; then
            echo "âœ… Backup integrity check passed"
          else
            echo "âŒ Backup integrity check failed"
            exit 1
          fi

      - name: Upload backup to artifacts
        uses: actions/upload-artifact@v4
        with:
          name: staging-db-backup-${{ github.run_number }}
          path: ${{ env.BACKUP_FILE }}
          retention-days: 7

      - name: Backup Summary
        if: always()
        run: |
          echo "## Staging Database Backup Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "âœ… Backup completed successfully" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ“¦ Backup file: \`${{ env.BACKUP_FILE }}\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Timestamp:** $(date -u +'%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY

